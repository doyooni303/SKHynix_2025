{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â— 5. SKHynix PBL ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ â—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ ê°œìš”\n",
    "\n",
    "ì‹œê°„ëŒ€(timekey_hr) ë‚´ì—ì„œ ê³µì • ìˆœì„œ(oper_id)ë¥¼ ê³ ë ¤í•œ ì‹œí€€ìŠ¤ ê¸°ë°˜ TAT ì˜ˆì¸¡ ëª¨ë¸ì…ë‹ˆë‹¤. ë™ì¼í•œ timekey_hr ë‚´ì˜ oper_idë“¤ì„ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ êµ¬ì„±í•˜ê³ , ê° operë³„ ê°œë³„ ì˜ˆì¸¡(sequence-to-sequence)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ë°ì´í„° êµ¬ì¡°**: `[batch_size, sequence_length, feature_dim]`\n",
    "- **sequence_length**: timekey_hr ë‚´ ìµœëŒ€ oper_id ê°œìˆ˜ (í•˜ì´í¼íŒŒë¼ë¯¸í„°)\n",
    "- **feature_dim**: ì—°ì†í˜• ë³€ìˆ˜ ê°œìˆ˜ + ë²”ì£¼í˜• ë³€ìˆ˜ ê°œìˆ˜ Ã— ì„ë² ë”© ì°¨ì›\n",
    "\n",
    "**ì§€ì› ëª¨ë¸**:\n",
    "1. **RNN/LSTM/GRU**: ê¸°ë³¸ ìˆœí™˜ ì‹ ê²½ë§\n",
    "2. **RNN + Self-Attention**: ìˆœí™˜ ì‹ ê²½ë§ì— ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€\n",
    "3. **CNN 1D**: ë‹¤ì¤‘ ì»¤ë„ 1ì°¨ì› í•©ì„±ê³± ì‹ ê²½ë§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# PyTorch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "\n",
    "### ì„¤ì • ë¡œë”© ë° ì‹œë“œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_dir: str = \"configs\") -> Dict:\n",
    "    \"\"\"YAML ì„¤ì • íŒŒì¼ë“¤ì„ í†µí•©í•˜ì—¬ ë¡œë“œ\"\"\"\n",
    "    configs = {}\n",
    "    config_files = [\"dataset\", \"model\", \"training\"]\n",
    "\n",
    "    for file in config_files:\n",
    "        config_path = os.path.join(config_dir, f\"{file}.yaml\")\n",
    "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "            configs.update(config)\n",
    "\n",
    "    return configs\n",
    "\n",
    "\n",
    "def set_random_seeds(seed: int = 42):\n",
    "    \"\"\"ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ ì„¤ì •\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def setup_logging(log_file: str = \"training.log\"):\n",
    "    \"\"\"ë¡œê¹… ì„¤ì •\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalProcessor:\n",
    "    \"\"\"ë²”ì£¼í˜• ë³€ìˆ˜ ì„ë² ë”©ì„ ìœ„í•œ ì²˜ë¦¬ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 8):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.label_encoders = {}\n",
    "        self.vocab_sizes = {}\n",
    "        self.categorical_columns = []\n",
    "        \n",
    "    def fit(self, df: pd.DataFrame, categorical_columns: List[str]):\n",
    "        \"\"\"ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ë²”ì£¼í˜• ì¸ì½”ë” í•™ìŠµ\"\"\"\n",
    "        self.categorical_columns = categorical_columns\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "            unique_values = df[col].astype(str).unique()\n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(unique_values)\n",
    "            \n",
    "            self.label_encoders[col] = encoder\n",
    "            self.vocab_sizes[col] = len(encoder.classes_)\n",
    "        \n",
    "        logger.info(f\"ë²”ì£¼í˜• ë³€ìˆ˜ë³„ ê³ ìœ ê°’ ê°œìˆ˜:\")\n",
    "        for col in categorical_columns:\n",
    "            logger.info(f\"  {col}: {self.vocab_sizes[col]}ê°œ\")\n",
    "    \n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"DataFrameì˜ ë²”ì£¼í˜• ì»¬ëŸ¼ë“¤ì„ ìˆ«ìë¡œ ë³€í™˜\"\"\"\n",
    "        df_encoded = df.copy()\n",
    "        \n",
    "        for col in self.categorical_columns:\n",
    "            df_encoded[col] = self.label_encoders[col].transform(\n",
    "                df_encoded[col].astype(str)\n",
    "            )\n",
    "        \n",
    "        return df_encoded\n",
    "    \n",
    "    def get_vocab_sizes(self) -> List[int]:\n",
    "        \"\"\"ê° ë²”ì£¼í˜• ë³€ìˆ˜ì˜ vocab_size ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\"\"\"\n",
    "        return [self.vocab_sizes[col] for col in self.categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
    "\n",
    "### ë©”ì¸ ë°ì´í„°ì…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceOperDataset(Dataset):\n",
    "    \"\"\"ì‹œí€€ìŠ¤ ê¸°ë°˜ oper ë°ì´í„°ì…‹\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        categorical_columns: List[str],\n",
    "        continuous_columns: List[str],\n",
    "        target_column: str = \"y\",\n",
    "        categorical_processor: Optional[CategoricalProcessor] = None,\n",
    "        max_sequence_length: int = 50,\n",
    "        embedding_dim: int = 8,\n",
    "        padding_value: float = -999999.0\n",
    "    ):\n",
    "        self.df = df.copy()\n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.continuous_columns = continuous_columns\n",
    "        self.target_column = target_column\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.padding_value = padding_value\n",
    "        \n",
    "        # ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬ê¸° ì„¤ì •\n",
    "        if categorical_processor is None:\n",
    "            self.categorical_processor = CategoricalProcessor(embedding_dim)\n",
    "            self.categorical_processor.fit(df, categorical_columns)\n",
    "        else:\n",
    "            self.categorical_processor = categorical_processor\n",
    "        \n",
    "        # ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œí€€ìŠ¤ ìƒì„±\n",
    "        self._preprocess_data()\n",
    "        self._create_sequences()\n",
    "        \n",
    "        logger.info(f\"ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ:\")\n",
    "        logger.info(f\"  - ì´ ì‹œí€€ìŠ¤ ìˆ˜: {len(self.sequences)}\")\n",
    "        logger.info(f\"  - ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {max_sequence_length}\")\n",
    "        logger.info(f\"  - íŠ¹ì„± ì°¨ì›: {self.feature_dim}\")\n",
    "        logger.info(f\"  - íŒ¨ë”©ê°’: {padding_value}\")\n",
    "    \n",
    "    def _preprocess_data(self):\n",
    "        \"\"\"ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
    "        # ë²”ì£¼í˜• ë°ì´í„° ì¸ì½”ë”©\n",
    "        if self.categorical_columns:\n",
    "            categorical_encoded = self.categorical_processor.transform(\n",
    "                self.df[self.categorical_columns]\n",
    "            )\n",
    "            self.df[self.categorical_columns] = categorical_encoded\n",
    "        \n",
    "        # íŠ¹ì„± ì°¨ì› ê³„ì‚°\n",
    "        continuous_dim = len(self.continuous_columns)\n",
    "        categorical_dim = len(self.categorical_columns) * self.embedding_dim\n",
    "        self.feature_dim = continuous_dim + categorical_dim\n",
    "    \n",
    "    def _create_sequences(self):\n",
    "        \"\"\"timekey_hrë³„ë¡œ oper_id ìˆœì„œ ê¸°ì¤€ ì‹œí€€ìŠ¤ ìƒì„±\"\"\"\n",
    "        self.sequences = []\n",
    "        \n",
    "        # timekey_hrë³„ë¡œ ê·¸ë£¹í™”\n",
    "        grouped = self.df.groupby('timekey_hr')\n",
    "        \n",
    "        for timekey_hr, group in grouped:\n",
    "            # oper_id ìˆœì„œë¡œ ì •ë ¬\n",
    "            group_sorted = group.sort_values('oper_id').reset_index(drop=True)\n",
    "            \n",
    "            if len(group_sorted) == 0:\n",
    "                continue\n",
    "            \n",
    "            # ì—°ì†í˜• ë°ì´í„° ì¶”ì¶œ\n",
    "            if self.continuous_columns:\n",
    "                continuous_data = group_sorted[self.continuous_columns].values\n",
    "            else:\n",
    "                continuous_data = np.empty((len(group_sorted), 0))\n",
    "            \n",
    "            # ë²”ì£¼í˜• ë°ì´í„° ì¶”ì¶œ (ë‚˜ì¤‘ì— ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜)\n",
    "            if self.categorical_columns:\n",
    "                categorical_data = group_sorted[self.categorical_columns].values\n",
    "            else:\n",
    "                categorical_data = np.empty((len(group_sorted), 0))\n",
    "            \n",
    "            # íƒ€ê²Ÿ ë°ì´í„° ì¶”ì¶œ\n",
    "            target_data = group_sorted[self.target_column].values\n",
    "            \n",
    "            # oper_id ì •ë³´ (ë””ë²„ê¹…ìš©)\n",
    "            oper_ids = group_sorted['oper_id'].values\n",
    "            \n",
    "            sequence_info = {\n",
    "                'timekey_hr': timekey_hr,\n",
    "                'continuous_data': continuous_data,\n",
    "                'categorical_data': categorical_data,\n",
    "                'target_data': target_data,\n",
    "                'oper_ids': oper_ids,\n",
    "                'sequence_length': len(group_sorted)\n",
    "            }\n",
    "            \n",
    "            self.sequences.append(sequence_info)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        \n",
    "        return {\n",
    "            'continuous_data': sequence['continuous_data'],\n",
    "            'categorical_data': sequence['categorical_data'], \n",
    "            'target_data': sequence['target_data'],\n",
    "            'sequence_length': sequence['sequence_length'],\n",
    "            'timekey_hr': sequence['timekey_hr'],\n",
    "            'oper_ids': sequence['oper_ids']\n",
    "        }\n",
    "\n",
    "\n",
    "def sequence_collate_fn(batch, max_sequence_length: int, padding_value: float = -999999.0):\n",
    "    \"\"\"ì‹œí€€ìŠ¤ ë°°ì¹˜ë¥¼ ìœ„í•œ íŒ¨ë”© í•¨ìˆ˜ (êµ¬ì¡° ì •ë³´ í¬í•¨)\"\"\"\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ ìƒ˜í”Œì—ì„œ ì°¨ì› ì •ë³´ ì¶”ì¶œ\n",
    "    first_sample = batch[0]\n",
    "    continuous_dim = first_sample['continuous_data'].shape[1]\n",
    "    categorical_dim = first_sample['categorical_data'].shape[1]\n",
    "    \n",
    "    # ê¸°ì¡´ ë°ì´í„° íŒ¨ë”©\n",
    "    batch_continuous = np.full(\n",
    "        (batch_size, max_sequence_length, continuous_dim), \n",
    "        padding_value, dtype=np.float32\n",
    "    )\n",
    "    batch_categorical = np.full(\n",
    "        (batch_size, max_sequence_length, categorical_dim), \n",
    "        0, dtype=np.int64\n",
    "    )\n",
    "    batch_targets = np.full(\n",
    "        (batch_size, max_sequence_length), \n",
    "        padding_value, dtype=np.float32\n",
    "    )\n",
    "    batch_masks = np.ones(\n",
    "        (batch_size, max_sequence_length), \n",
    "        dtype=bool\n",
    "    )\n",
    "    \n",
    "    # êµ¬ì¡° ì •ë³´ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ë“¤ ì¶”ê°€\n",
    "    batch_timekey_hrs = []\n",
    "    batch_oper_ids_list = []\n",
    "    batch_lengths = []\n",
    "    \n",
    "    for i, sample in enumerate(batch):\n",
    "        seq_len = min(sample['sequence_length'], max_sequence_length)\n",
    "        batch_lengths.append(seq_len)\n",
    "        \n",
    "        # ê¸°ì¡´ ë°ì´í„° ì±„ìš°ê¸°\n",
    "        batch_continuous[i, :seq_len] = sample['continuous_data'][:seq_len]\n",
    "        batch_categorical[i, :seq_len] = sample['categorical_data'][:seq_len]  \n",
    "        batch_targets[i, :seq_len] = sample['target_data'][:seq_len]\n",
    "        batch_masks[i, :seq_len] = False\n",
    "        \n",
    "        # êµ¬ì¡° ì •ë³´ ì¶”ê°€\n",
    "        batch_timekey_hrs.append(sample['timekey_hr'])\n",
    "        # max_sequence_lengthë§Œí¼ oper_id ë¦¬ìŠ¤íŠ¸ ìƒì„± (íŒ¨ë”©ëœ ë¶€ë¶„ì€ None)\n",
    "        oper_ids_padded = list(sample['oper_ids'][:seq_len])\n",
    "        while len(oper_ids_padded) < max_sequence_length:\n",
    "            oper_ids_padded.append(None)\n",
    "        batch_oper_ids_list.append(oper_ids_padded)\n",
    "    \n",
    "    return {\n",
    "        'continuous_data': torch.tensor(batch_continuous),\n",
    "        'categorical_data': torch.tensor(batch_categorical),\n",
    "        'targets': torch.tensor(batch_targets),\n",
    "        'masks': torch.tensor(batch_masks),\n",
    "        'sequence_lengths': batch_lengths,\n",
    "        'timekey_hrs': batch_timekey_hrs,  \n",
    "        'oper_ids_list': batch_oper_ids_list\n",
    "    }\n",
    "\n",
    "\n",
    "def create_dataloaders(dataset_config: Dict) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \"\"\"ë°ì´í„°ë¡œë” ìƒì„±\"\"\"\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "    data_path = dataset_config[\"file_path\"]\n",
    "    excel = pd.read_excel(data_path, sheet_name=None, header=1)\n",
    "    sheet_names = dataset_config[\"sheet_names\"]\n",
    "    \n",
    "    total_df = pd.concat([excel[sheet_name] for sheet_name in sheet_names])\n",
    "    \n",
    "    # ê¸°ë³¸ ì „ì²˜ë¦¬\n",
    "    if \"Unnamed: 0\" in total_df.columns:\n",
    "        total_df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    \n",
    "    # yê°’ ê²°ì¸¡ì¹˜ ì œê±°\n",
    "    df = total_df[~total_df[dataset_config[\"target_column\"]].isna()].copy()\n",
    "    \n",
    "    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°\n",
    "    drop_columns = dataset_config.get(\"additional_drop_columns\", [])\n",
    "    if drop_columns:\n",
    "        existing_drops = [col for col in drop_columns if col in df.columns]\n",
    "        if existing_drops:\n",
    "            df = df.drop(columns=existing_drops)\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ë²”ì£¼í˜• ì²˜ë¦¬ê¸° í•™ìŠµ\n",
    "    categorical_processor = CategoricalProcessor(\n",
    "        embedding_dim=dataset_config.get(\"embedding_dim\", 8)\n",
    "    )\n",
    "    categorical_processor.fit(df, dataset_config[\"categorical_columns\"])\n",
    "    \n",
    "    # ë°ì´í„° ë¶„í•  (8:1:1)\n",
    "    total_size = len(df)\n",
    "    train_end = int(total_size * dataset_config.get(\"train_ratio\", 0.8))\n",
    "    val_end = int(total_size * (dataset_config.get(\"train_ratio\", 0.8) + dataset_config.get(\"val_ratio\", 0.1)))\n",
    "    \n",
    "    train_df = df[:train_end].copy()\n",
    "    val_df = df[train_end:val_end].copy()\n",
    "    test_df = df[val_end:].copy()\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ ìƒì„±\n",
    "    train_dataset = SequenceOperDataset(\n",
    "        df=train_df,\n",
    "        categorical_columns=dataset_config[\"categorical_columns\"],\n",
    "        continuous_columns=dataset_config[\"continuous_columns\"],\n",
    "        target_column=dataset_config[\"target_column\"],\n",
    "        categorical_processor=categorical_processor,\n",
    "        max_sequence_length=dataset_config.get(\"max_sequence_length\", 50),\n",
    "        embedding_dim=dataset_config.get(\"embedding_dim\", 8),\n",
    "        padding_value=dataset_config.get(\"padding_value\", -999999.0)\n",
    "    )\n",
    "    \n",
    "    val_dataset = SequenceOperDataset(\n",
    "        df=val_df,\n",
    "        categorical_columns=dataset_config[\"categorical_columns\"],\n",
    "        continuous_columns=dataset_config[\"continuous_columns\"], \n",
    "        target_column=dataset_config[\"target_column\"],\n",
    "        categorical_processor=categorical_processor,\n",
    "        max_sequence_length=dataset_config.get(\"max_sequence_length\", 50),\n",
    "        embedding_dim=dataset_config.get(\"embedding_dim\", 8),\n",
    "        padding_value=dataset_config.get(\"padding_value\", -999999.0)\n",
    "    )\n",
    "    \n",
    "    test_dataset = SequenceOperDataset(\n",
    "        df=test_df,\n",
    "        categorical_columns=dataset_config[\"categorical_columns\"],\n",
    "        continuous_columns=dataset_config[\"continuous_columns\"],\n",
    "        target_column=dataset_config[\"target_column\"], \n",
    "        categorical_processor=categorical_processor,\n",
    "        max_sequence_length=dataset_config.get(\"max_sequence_length\", 50),\n",
    "        embedding_dim=dataset_config.get(\"embedding_dim\", 8),\n",
    "        padding_value=dataset_config.get(\"padding_value\", -999999.0)\n",
    "    )\n",
    "    \n",
    "    # Collate í•¨ìˆ˜ ì„¤ì •\n",
    "    def collate_fn(batch):\n",
    "        return sequence_collate_fn(\n",
    "            batch, \n",
    "            max_sequence_length=dataset_config.get(\"max_sequence_length\", 50),\n",
    "            padding_value=dataset_config.get(\"padding_value\", -999999.0)\n",
    "        )\n",
    "    \n",
    "    # ë°ì´í„°ë¡œë” ìƒì„±\n",
    "    batch_size = dataset_config.get(\"batch_size\", 32)\n",
    "    num_workers = dataset_config.get(\"num_workers\", 4)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ:\")\n",
    "    logger.info(f\"  - í›ˆë ¨ ìƒ˜í”Œ: {len(train_dataset)}\")\n",
    "    logger.info(f\"  - ê²€ì¦ ìƒ˜í”Œ: {len(val_dataset)}\")\n",
    "    logger.info(f\"  - í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(test_dataset)}\")\n",
    "    logger.info(f\"  - ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, categorical_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.read_excel(\"/home/doyooni303/teaching/SK_Hynix/PBL_TAT_Set_Data Rev2(ì‚¬ì™¸).xlsx\", sheet_name=None, header=1)\n",
    "\n",
    "total = pd.concat([excel[sheet_name] for sheet_name in [\"Data_Set1(ì‚¬ì™¸)\",\"Data_Set2(ì‚¬ì™¸)\"]] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtotal\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total' is not defined"
     ]
    }
   ],
   "source": [
    "total.drop(columns=\"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ëª¨ë¸ë§\")\n",
    "parser.add_argument(\"--config-dir\", default=\"configs\", help=\"ì„¤ì • íŒŒì¼ ë””ë ‰í† ë¦¬\")\n",
    "parser.add_argument(\"--mode\", choices=[\"train\", \"eval\"], default=\"train\", help=\"ì‹¤í–‰ ëª¨ë“œ\")\n",
    "parser.add_argument(\"--model-path\", default=None, help=\"í‰ê°€ìš© ëª¨ë¸ ê²½ë¡œ\")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"GPU ë²ˆí˜¸\")\n",
    "parser.add_argument(\"--exp-name\", default=\"code-test\", help=\"ì‹¤í—˜ëª…\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# ì„¤ì • ë¡œë“œ\n",
    "config = load_config(args.config_dir)\n",
    "set_random_seeds(42)\n",
    "\n",
    "# ì‹¤í—˜ëª… ì„¤ì •\n",
    "if args.exp_name:\n",
    "    exp_name = args.exp_name\n",
    "else:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_type = config.get(\"model_type\", \"lstm\")\n",
    "    exp_name = f\"{model_type}_{timestamp}\"\n",
    "\n",
    "# ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "save_dir = config.get(\"save_dir\", \"models\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_save_path = os.path.join(save_dir, f\"{exp_name}.pth\")\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(f\"cuda:{args.gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# ë°ì´í„°ë¡œë” ìƒì„±\n",
    "logger.info(\"ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "train_loader, val_loader, test_loader, categorical_processor = create_dataloaders(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ë“¤\n",
    "\n",
    "### RNN ê¸°ë³¸ ëª¨ë¸ (models/rnn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \"\"\"ê¸°ë³¸ RNN/LSTM/GRU ëª¨ë¸\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_sizes: List[int],  # ê° ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê³ ìœ ê°’ ê°œìˆ˜ ë¦¬ìŠ¤íŠ¸ [277, 7, 3, 20]\n",
    "        continuous_dim: int,\n",
    "        embedding_dim: int = 8,\n",
    "        rnn_type: str = \"LSTM\",\n",
    "        hidden_dim: int = 128,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.1,\n",
    "        bidirectional: bool = True,\n",
    "        padding_value: float = -999999.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.padding_value = padding_value\n",
    "        self.num_categorical_vars = len(vocab_sizes)  # ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê°œìˆ˜\n",
    "        \n",
    "        # ê° ë²”ì£¼í˜• ë³€ìˆ˜ë³„ë¡œ ë³„ë„ì˜ ì„ë² ë”© ë ˆì´ì–´ ìƒì„±\n",
    "        # ì˜ˆ: oper_group(277) -> 8ì°¨ì›, days(7) -> 8ì°¨ì›, shift(3) -> 8ì°¨ì›, x1(20) -> 8ì°¨ì›\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "            for vocab_size in vocab_sizes\n",
    "        ])\n",
    "        \n",
    "        # ì…ë ¥ ì°¨ì› = ì—°ì†í˜• ì°¨ì› + (ë²”ì£¼í˜• ë³€ìˆ˜ ê°œìˆ˜ Ã— ì„ë² ë”© ì°¨ì›)\n",
    "        # ì˜ˆ: continuous_dim=20, num_categorical_vars=4, embedding_dim=8\n",
    "        # â†’ input_dim = 20 + 4*8 = 52\n",
    "        input_dim = continuous_dim + self.num_categorical_vars * embedding_dim\n",
    "        \n",
    "        # RNN ë ˆì´ì–´\n",
    "        if rnn_type.upper() == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_dim, hidden_dim, num_layers,\n",
    "                batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional\n",
    "            )\n",
    "        elif rnn_type.upper() == \"GRU\":\n",
    "            self.rnn = nn.GRU(\n",
    "                input_dim, hidden_dim, num_layers,\n",
    "                batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional\n",
    "            )\n",
    "        else:  # RNN\n",
    "            self.rnn = nn.RNN(\n",
    "                input_dim, hidden_dim, num_layers,\n",
    "                batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional\n",
    "            )\n",
    "        \n",
    "        # ì¶œë ¥ ì°¨ì› ê³„ì‚°\n",
    "        rnn_output_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, continuous_data, categorical_data, masks, sequence_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            continuous_data: [batch_size, seq_len, continuous_dim]\n",
    "            categorical_data: [batch_size, seq_len, num_categorical_vars] (ê° ìœ„ì¹˜ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ì¸ë±ìŠ¤)\n",
    "            masks: [batch_size, seq_len] (True = íŒ¨ë”©)\n",
    "            sequence_lengths: [batch_size] \n",
    "        \"\"\"\n",
    "        batch_size, seq_len = continuous_data.shape[:2]\n",
    "        \n",
    "        # ê° ë²”ì£¼í˜• ë³€ìˆ˜ë³„ë¡œ ì„ë² ë”© ì ìš©\n",
    "        # categorical_data[:, :, 0] = oper_group ì¸ë±ìŠ¤ë“¤ â†’ 8ì°¨ì› ì„ë² ë”©\n",
    "        # categorical_data[:, :, 1] = days ì¸ë±ìŠ¤ë“¤ â†’ 8ì°¨ì› ì„ë² ë”©  \n",
    "        # categorical_data[:, :, 2] = shift ì¸ë±ìŠ¤ë“¤ â†’ 8ì°¨ì› ì„ë² ë”©\n",
    "        # categorical_data[:, :, 3] = x1 ì¸ë±ìŠ¤ë“¤ â†’ 8ì°¨ì› ì„ë² ë”©\n",
    "        embedded_categorical = []\n",
    "        for i, embedding_layer in enumerate(self.embeddings):\n",
    "            # categorical_data[:, :, i]: [batch_size, seq_len] â†’ [batch_size, seq_len, embedding_dim]\n",
    "            embedded = embedding_layer(categorical_data[:, :, i])\n",
    "            embedded_categorical.append(embedded)\n",
    "        \n",
    "        if embedded_categorical:\n",
    "            # ëª¨ë“  ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ì„ë² ë”©ì„ concatenate\n",
    "            # [batch_size, seq_len, num_categorical_vars * embedding_dim]\n",
    "            categorical_embedded = torch.cat(embedded_categorical, dim=-1)\n",
    "        else:\n",
    "            categorical_embedded = torch.empty(batch_size, seq_len, 0, device=continuous_data.device)\n",
    "        \n",
    "        # ì—°ì†í˜•ê³¼ ë²”ì£¼í˜• ê²°í•©\n",
    "        # [batch_size, seq_len, continuous_dim + num_categorical_vars * embedding_dim]\n",
    "        combined_input = torch.cat([continuous_data, categorical_embedded], dim=-1)\n",
    "        \n",
    "        # íŒ¨ë”©ëœ ìœ„ì¹˜ë¥¼ ë§ˆìŠ¤í‚¹\n",
    "        combined_input = combined_input.masked_fill(\n",
    "            masks.unsqueeze(-1), self.padding_value\n",
    "        )\n",
    "        \n",
    "        # RNN forward\n",
    "        rnn_output, _ = self.rnn(combined_input)\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        predictions = self.output_layer(rnn_output).squeeze(-1)\n",
    "        \n",
    "        # íŒ¨ë”©ëœ ìœ„ì¹˜ëŠ” 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹\n",
    "        predictions = predictions.masked_fill(masks, 0.0)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN + Self-Attention ëª¨ë¸ (models/attention.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"Self-Attention ë©”ì»¤ë‹ˆì¦˜\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim: int, num_heads: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        \n",
    "        assert hidden_dim % num_heads == 0, \"hidden_dim must be divisible by num_heads\"\n",
    "        \n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, hidden_dim]\n",
    "            mask: [batch_size, seq_len] (True = íŒ¨ë”©)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Multi-head attention\n",
    "        Q = self.query(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.key(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.value(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Attention scores\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.head_dim)\n",
    "        \n",
    "        # Apply mask\n",
    "        if mask is not None:\n",
    "            attention_mask = mask.unsqueeze(1).unsqueeze(1)  # [batch, 1, 1, seq_len]\n",
    "            attention_scores = attention_scores.masked_fill(attention_mask, float('-inf'))\n",
    "        \n",
    "        # Softmax\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        \n",
    "        # Apply attention\n",
    "        attended = torch.matmul(attention_weights, V)\n",
    "        attended = attended.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)\n",
    "        \n",
    "        # Residual connection + Layer norm\n",
    "        output = self.layer_norm(x + attended)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class RNNAttentionModel(nn.Module):\n",
    "    \"\"\"RNN + Self-Attention ëª¨ë¸\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_sizes: List[int],  # ê° ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê³ ìœ ê°’ ê°œìˆ˜ ë¦¬ìŠ¤íŠ¸ [277, 7, 3, 20]\n",
    "        continuous_dim: int,\n",
    "        embedding_dim: int = 8,\n",
    "        rnn_type: str = \"LSTM\", \n",
    "        hidden_dim: int = 128,\n",
    "        num_layers: int = 2,\n",
    "        num_attention_heads: int = 8,\n",
    "        dropout: float = 0.1,\n",
    "        bidirectional: bool = True,\n",
    "        padding_value: float = -999999.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.padding_value = padding_value\n",
    "        self.num_categorical_vars = len(vocab_sizes)  # ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê°œìˆ˜\n",
    "        \n",
    "        # ê° ë²”ì£¼í˜• ë³€ìˆ˜ë³„ë¡œ ë³„ë„ì˜ ì„ë² ë”© ë ˆì´ì–´ ìƒì„±\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "            for vocab_size in vocab_sizes\n",
    "        ])\n",
    "        \n",
    "        # ì…ë ¥ ì°¨ì› = ì—°ì†í˜• ì°¨ì› + (ë²”ì£¼í˜• ë³€ìˆ˜ ê°œìˆ˜ Ã— ì„ë² ë”© ì°¨ì›)\n",
    "        input_dim = continuous_dim + self.num_categorical_vars * embedding_dim\n",
    "        \n",
    "        # RNN ë ˆì´ì–´\n",
    "        if rnn_type.upper() == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_dim, hidden_dim, num_layers,\n",
    "                batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional\n",
    "            )\n",
    "        elif rnn_type.upper() == \"GRU\":\n",
    "            self.rnn = nn.GRU(\n",
    "                input_dim, hidden_dim, num_layers,\n",
    "                batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional\n",
    "            )\n",
    "        else:  # RNN\n",
    "            self.rnn = nn.RNN(\n",
    "                input_dim, hidden_dim, num_layers,\n",
    "                batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional\n",
    "            )\n",
    "        \n",
    "        # RNN ì¶œë ¥ ì°¨ì›\n",
    "        rnn_output_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "        \n",
    "        # RNN ì¶œë ¥ì„ ì–´í…ì…˜ ì…ë ¥ ì°¨ì›ìœ¼ë¡œ ë³€í™˜\n",
    "        self.rnn_projection = nn.Linear(rnn_output_dim, hidden_dim)\n",
    "        \n",
    "        # Self-Attention\n",
    "        self.self_attention = SelfAttention(\n",
    "            hidden_dim, num_attention_heads, dropout\n",
    "        )\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, continuous_data, categorical_data, masks, sequence_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            continuous_data: [batch_size, seq_len, continuous_dim]\n",
    "            categorical_data: [batch_size, seq_len, num_categorical]\n",
    "            masks: [batch_size, seq_len] (True = íŒ¨ë”©)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = continuous_data.shape[:2]\n",
    "        \n",
    "        # ë²”ì£¼í˜• ë°ì´í„° ì„ë² ë”©\n",
    "        embedded_categorical = []\n",
    "        for i, embedding in enumerate(self.embeddings):\n",
    "            embedded = embedding(categorical_data[:, :, i])\n",
    "            embedded_categorical.append(embedded)\n",
    "        \n",
    "        if embedded_categorical:\n",
    "            categorical_embedded = torch.cat(embedded_categorical, dim=-1)\n",
    "        else:\n",
    "            categorical_embedded = torch.empty(batch_size, seq_len, 0, device=continuous_data.device)\n",
    "        \n",
    "        # ì—°ì†í˜•ê³¼ ë²”ì£¼í˜• ê²°í•©\n",
    "        combined_input = torch.cat([continuous_data, categorical_embedded], dim=-1)\n",
    "        \n",
    "        # íŒ¨ë”©ëœ ìœ„ì¹˜ë¥¼ ë§ˆìŠ¤í‚¹\n",
    "        combined_input = combined_input.masked_fill(\n",
    "            masks.unsqueeze(-1), self.padding_value\n",
    "        )\n",
    "        \n",
    "        # RNN forward\n",
    "        rnn_output, _ = self.rnn(combined_input)\n",
    "        \n",
    "        # RNN ì¶œë ¥ ì°¨ì› ë³€í™˜\n",
    "        projected_output = self.rnn_projection(rnn_output)\n",
    "        \n",
    "        # Self-Attention ì ìš©\n",
    "        attended_output = self.self_attention(projected_output, masks)\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        predictions = self.output_layer(attended_output).squeeze(-1)\n",
    "        \n",
    "        # íŒ¨ë”©ëœ ìœ„ì¹˜ëŠ” 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹\n",
    "        predictions = predictions.masked_fill(masks, 0.0)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 1D ëª¨ë¸ (models/cnn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DModel(nn.Module):\n",
    "    \"\"\"1D CNN ëª¨ë¸ (ë‹¤ì¤‘ ì»¤ë„)\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_sizes: List[int],  # ê° ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê³ ìœ ê°’ ê°œìˆ˜ ë¦¬ìŠ¤íŠ¸ [277, 7, 3, 20]\n",
    "        continuous_dim: int,\n",
    "        embedding_dim: int = 8,\n",
    "        kernel_sizes: List[int] = [3, 5, 7],\n",
    "        num_filters: int = 64,\n",
    "        dropout: float = 0.1,\n",
    "        padding_value: float = -999999.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.num_filters = num_filters\n",
    "        self.padding_value = padding_value\n",
    "        self.num_categorical_vars = len(vocab_sizes)  # ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê°œìˆ˜\n",
    "        \n",
    "        # ê° ë²”ì£¼í˜• ë³€ìˆ˜ë³„ë¡œ ë³„ë„ì˜ ì„ë² ë”© ë ˆì´ì–´ ìƒì„±\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "            for vocab_size in vocab_sizes\n",
    "        ])\n",
    "        \n",
    "        # ì…ë ¥ ì°¨ì› = ì—°ì†í˜• ì°¨ì› + (ë²”ì£¼í˜• ë³€ìˆ˜ ê°œìˆ˜ Ã— ì„ë² ë”© ì°¨ì›)\n",
    "        input_dim = continuous_dim + self.num_categorical_vars * embedding_dim\n",
    "        \n",
    "        # ë‹¤ì¤‘ ì»¤ë„ 1D Conv ë ˆì´ì–´ë“¤\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(input_dim, num_filters, kernel_size, padding=kernel_size//2)\n",
    "            for kernel_size in kernel_sizes\n",
    "        ])\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(num_filters) for _ in kernel_sizes\n",
    "        ])\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        total_filters = len(kernel_sizes) * num_filters\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(total_filters, total_filters // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(total_filters // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, continuous_data, categorical_data, masks, sequence_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            continuous_data: [batch_size, seq_len, continuous_dim]\n",
    "            categorical_data: [batch_size, seq_len, num_categorical]\n",
    "            masks: [batch_size, seq_len] (True = íŒ¨ë”©)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = continuous_data.shape[:2]\n",
    "        \n",
    "        # ë²”ì£¼í˜• ë°ì´í„° ì„ë² ë”©\n",
    "        embedded_categorical = []\n",
    "        for i, embedding in enumerate(self.embeddings):\n",
    "            embedded = embedding(categorical_data[:, :, i])\n",
    "            embedded_categorical.append(embedded)\n",
    "        \n",
    "        if embedded_categorical:\n",
    "            categorical_embedded = torch.cat(embedded_categorical, dim=-1)\n",
    "        else:\n",
    "            categorical_embedded = torch.empty(batch_size, seq_len, 0, device=continuous_data.device)\n",
    "        \n",
    "        # ì—°ì†í˜•ê³¼ ë²”ì£¼í˜• ê²°í•©\n",
    "        combined_input = torch.cat([continuous_data, categorical_embedded], dim=-1)\n",
    "        \n",
    "        # íŒ¨ë”©ëœ ìœ„ì¹˜ë¥¼ ë§ˆìŠ¤í‚¹\n",
    "        combined_input = combined_input.masked_fill(\n",
    "            masks.unsqueeze(-1), self.padding_value\n",
    "        )\n",
    "        \n",
    "        # Conv1dë¥¼ ìœ„í•´ ì°¨ì› ë³€í™˜: [batch, seq_len, features] -> [batch, features, seq_len]\n",
    "        conv_input = combined_input.transpose(1, 2)\n",
    "        \n",
    "        # ë‹¤ì¤‘ ì»¤ë„ Conv1D ì ìš©\n",
    "        conv_outputs = []\n",
    "        for conv, bn in zip(self.conv_layers, self.batch_norms):\n",
    "            conv_out = F.relu(bn(conv(conv_input)))  # [batch, filters, seq_len]\n",
    "            conv_outputs.append(conv_out)\n",
    "        \n",
    "        # ëª¨ë“  ì»¤ë„ ì¶œë ¥ ê²°í•©\n",
    "        combined_conv = torch.cat(conv_outputs, dim=1)  # [batch, total_filters, seq_len]\n",
    "        \n",
    "        # ë‹¤ì‹œ ì›ë˜ ì°¨ì›ìœ¼ë¡œ: [batch, total_filters, seq_len] -> [batch, seq_len, total_filters]\n",
    "        combined_conv = combined_conv.transpose(1, 2)\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        predictions = self.output_layer(combined_conv).squeeze(-1)\n",
    "        \n",
    "        # íŒ¨ë”©ëœ ìœ„ì¹˜ëŠ” 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹\n",
    "        predictions = predictions.masked_fill(masks, 0.0)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ íŒ©í† ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_config: Dict, vocab_sizes: List[int], continuous_dim: int):\n",
    "    \"\"\"ì„¤ì •ì— ë”°ë¥¸ ëª¨ë¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    model_type = model_config.get(\"model_type\", \"lstm\").lower()\n",
    "    embedding_dim = model_config.get(\"embedding_dim\", 8)\n",
    "    hidden_dim = model_config.get(\"hidden_dim\", 128)\n",
    "    num_layers = model_config.get(\"num_layers\", 2)\n",
    "    dropout = model_config.get(\"dropout\", 0.1)\n",
    "    bidirectional = model_config.get(\"bidirectional\", True)\n",
    "    padding_value = model_config.get(\"padding_value\", -999999.0)\n",
    "    \n",
    "    if model_type in [\"rnn\", \"lstm\", \"gru\"]:\n",
    "        model = RNNModel(\n",
    "            vocab_sizes=vocab_sizes,\n",
    "            continuous_dim=continuous_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            rnn_type=model_type.upper(),\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional,\n",
    "            padding_value=padding_value\n",
    "        )\n",
    "        \n",
    "    elif model_type in [\"rnn_attention\", \"lstm_attention\", \"gru_attention\"]:\n",
    "        rnn_type = model_type.replace(\"_attention\", \"\").upper()\n",
    "        num_attention_heads = model_config.get(\"num_attention_heads\", 8)\n",
    "        \n",
    "        model = RNNAttentionModel(\n",
    "            vocab_sizes=vocab_sizes,\n",
    "            continuous_dim=continuous_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            rnn_type=rnn_type,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            num_attention_heads=num_attention_heads,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional,\n",
    "            padding_value=padding_value\n",
    "        )\n",
    "        \n",
    "    elif model_type == \"cnn1d\":\n",
    "        kernel_sizes = model_config.get(\"kernel_sizes\", [3, 5, 7])\n",
    "        num_filters = model_config.get(\"num_filters\", 64)\n",
    "        \n",
    "        model = CNN1DModel(\n",
    "            vocab_sizes=vocab_sizes,\n",
    "            continuous_dim=continuous_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            kernel_sizes=kernel_sizes,\n",
    "            num_filters=num_filters,\n",
    "            dropout=dropout,\n",
    "            padding_value=padding_value\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "    \n",
    "    logger.info(f\"ëª¨ë¸ ìƒì„± ì™„ë£Œ:\")\n",
    "    logger.info(f\"  - ëª¨ë¸ íƒ€ì…: {model_type}\")\n",
    "    logger.info(f\"  - ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    logger.info(f\"  - í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš‚ í›ˆë ¨ ë° í‰ê°€ í•¨ìˆ˜ë“¤\n",
    "\n",
    "### ë§ˆìŠ¤í¬ ê¸°ë°˜ ì†ì‹¤ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMSELoss(nn.Module):\n",
    "    \"\"\"íŒ¨ë”©ì„ ê³ ë ¤í•œ MSE Loss\"\"\"\n",
    "    \n",
    "    def __init__(self, padding_value: float = -999999.0):\n",
    "        super().__init__()\n",
    "        self.padding_value = padding_value\n",
    "    \n",
    "    def forward(self, predictions, targets, masks):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictions: [batch_size, seq_len]\n",
    "            targets: [batch_size, seq_len]  \n",
    "            masks: [batch_size, seq_len] (True = íŒ¨ë”©)\n",
    "        \"\"\"\n",
    "        # íŒ¨ë”©ë˜ì§€ ì•Šì€ ìœ„ì¹˜ë§Œ ì„ íƒ\n",
    "        valid_mask = ~masks\n",
    "        \n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True)\n",
    "        \n",
    "        valid_predictions = predictions[valid_mask]\n",
    "        valid_targets = targets[valid_mask]\n",
    "        \n",
    "        return F.mse_loss(valid_predictions, valid_targets)\n",
    "\n",
    "\n",
    "def compute_metrics(predictions, targets, masks, padding_value: float = -999999.0):\n",
    "    \"\"\"íŒ¨ë”©ì„ ê³ ë ¤í•œ ë©”íŠ¸ë¦­ ê³„ì‚°\"\"\"\n",
    "    valid_mask = ~masks\n",
    "    \n",
    "    if valid_mask.sum() == 0:\n",
    "        return {\"mse\": 0.0, \"rmse\": 0.0, \"mae\": 0.0, \"mape\": 0.0, \"valid_count\": 0}\n",
    "    \n",
    "    valid_predictions = predictions[valid_mask]\n",
    "    valid_targets = targets[valid_mask]\n",
    "    \n",
    "    # CPUë¡œ ë³€í™˜\n",
    "    valid_predictions = valid_predictions.detach().cpu().numpy()\n",
    "    valid_targets = valid_targets.detach().cpu().numpy()\n",
    "    \n",
    "    mse = np.mean((valid_predictions - valid_targets) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(valid_predictions - valid_targets))\n",
    "    \n",
    "    # MAPE ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)\n",
    "    epsilon = 1e-8\n",
    "    abs_targets = np.abs(valid_targets)\n",
    "    abs_errors = np.abs(valid_predictions - valid_targets)\n",
    "    safe_targets = np.maximum(abs_targets, epsilon)\n",
    "    mape = np.mean(abs_errors / safe_targets * 100)\n",
    "    \n",
    "    return {\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse, \n",
    "        \"mae\": mae,\n",
    "        \"mape\": mape,\n",
    "        \"valid_count\": len(valid_predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í›ˆë ¨ ì—í­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"í•œ ì—í­ í›ˆë ¨\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_metrics = {\"mse\": 0.0, \"rmse\": 0.0, \"mae\": 0.0, \"mape\": 0.0, \"valid_count\": 0}\n",
    "    \n",
    "    pbar = tqdm(\n",
    "        enumerate(dataloader), \n",
    "        total=len(dataloader),\n",
    "        desc=f\"Epoch {epoch} [Train]\",\n",
    "        leave=False\n",
    "    )\n",
    "    \n",
    "    for batch_idx, batch in pbar:\n",
    "        continuous_data = batch[\"continuous_data\"].to(device)\n",
    "        categorical_data = batch[\"categorical_data\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)\n",
    "        masks = batch[\"masks\"].to(device)\n",
    "        sequence_lengths = batch[\"sequence_lengths\"]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(continuous_data, categorical_data, masks, sequence_lengths)\n",
    "        loss = criterion(predictions, targets, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "        with torch.no_grad():\n",
    "            batch_metrics = compute_metrics(predictions, targets, masks)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        for key in [\"mse\", \"rmse\", \"mae\", \"mape\"]:\n",
    "            total_metrics[key] += batch_metrics[key]\n",
    "        total_metrics[\"valid_count\"] += batch_metrics[\"valid_count\"]\n",
    "        \n",
    "        # ì§„í–‰ë°” ì—…ë°ì´íŠ¸\n",
    "        pbar.set_postfix({\n",
    "            \"Loss\": f\"{loss.item():.4f}\",\n",
    "            \"MAPE\": f\"{batch_metrics['mape']:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # í‰ê·  ê³„ì‚°\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    for key in [\"mse\", \"rmse\", \"mae\", \"mape\"]:\n",
    "        total_metrics[key] = total_metrics[key] / len(dataloader)\n",
    "    \n",
    "    return avg_loss, total_metrics\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device, epoch=None):\n",
    "    \"\"\"ê²€ì¦ ì—í­\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_metrics = {\"mse\": 0.0, \"rmse\": 0.0, \"mae\": 0.0, \"mape\": 0.0, \"valid_count\": 0}\n",
    "    \n",
    "    desc = f\"Epoch {epoch} [Val]\" if epoch is not None else \"Validation\"\n",
    "    pbar = tqdm(dataloader, desc=desc, leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            continuous_data = batch[\"continuous_data\"].to(device)\n",
    "            categorical_data = batch[\"categorical_data\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "            masks = batch[\"masks\"].to(device)\n",
    "            sequence_lengths = batch[\"sequence_lengths\"]\n",
    "            \n",
    "            predictions = model(continuous_data, categorical_data, masks, sequence_lengths)\n",
    "            loss = criterion(predictions, targets, masks)\n",
    "            \n",
    "            batch_metrics = compute_metrics(predictions, targets, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            for key in [\"mse\", \"rmse\", \"mae\", \"mape\"]:\n",
    "                total_metrics[key] += batch_metrics[key]\n",
    "            total_metrics[\"valid_count\"] += batch_metrics[\"valid_count\"]\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                \"Loss\": f\"{loss.item():.4f}\",\n",
    "                \"MAPE\": f\"{batch_metrics['mape']:.2f}%\"\n",
    "            })\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    for key in [\"mse\", \"rmse\", \"mae\", \"mape\"]:\n",
    "        total_metrics[key] = total_metrics[key] / len(dataloader)\n",
    "    \n",
    "    return avg_loss, total_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë©”ì¸ í›ˆë ¨ ë£¨í”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, training_config, device, save_path):\n",
    "    \"\"\"ë©”ì¸ í›ˆë ¨ ë£¨í”„\"\"\"\n",
    "    \n",
    "    num_epochs = training_config.get(\"num_epochs\", 100)\n",
    "    learning_rate = training_config.get(\"learning_rate\", 1e-3)\n",
    "    patience = training_config.get(\"patience\", 20)\n",
    "    padding_value = training_config.get(\"padding_value\", -999999.0)\n",
    "    \n",
    "    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
    "    criterion = MaskedMSELoss(padding_value)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patience//2, verbose=True)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    logger.info(f\"í›ˆë ¨ ì‹œì‘: {num_epochs} ì—í­, í•™ìŠµë¥  {learning_rate}\")\n",
    "    \n",
    "    # ì—í­ ì§„í–‰ë°”\n",
    "    epoch_pbar = tqdm(range(1, num_epochs + 1), desc=\"Training Progress\")\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        train_loss, train_metrics = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, epoch\n",
    "        )\n",
    "        val_loss, val_metrics = validate_epoch(\n",
    "            model, val_loader, criterion, device, epoch\n",
    "        )\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # ë¡œê·¸ ì¶œë ¥\n",
    "        logger.info(\n",
    "            f\"Epoch {epoch:3d}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, \"\n",
    "            f'Train MAPE={train_metrics[\"mape\"]:.2f}%, Val MAPE={val_metrics[\"mape\"]:.2f}%'\n",
    "        )\n",
    "        \n",
    "        # ì§„í–‰ë°” ì—…ë°ì´íŠ¸\n",
    "        epoch_pbar.set_postfix({\n",
    "            \"T_Loss\": f\"{train_loss:.4f}\",\n",
    "            \"V_Loss\": f\"{val_loss:.4f}\",\n",
    "            \"V_MAPE\": f'{val_metrics[\"mape\"]:.2f}%',\n",
    "            \"Best\": f\"{best_val_loss:.4f}\",\n",
    "            \"Patience\": f\"{patience_counter}/{patience}\"\n",
    "        })\n",
    "        \n",
    "        # ìµœê³  ëª¨ë¸ ì €ì¥\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_metrics': val_metrics,\n",
    "                'train_metrics': train_metrics\n",
    "            }, save_path)\n",
    "            \n",
    "            logger.info(f\"  â†’ Best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # ì¡°ê¸° ì¢…ë£Œ\n",
    "        if patience_counter >= patience:\n",
    "            logger.info(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    epoch_pbar.close()\n",
    "    \n",
    "    return {\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, model_path):\n",
    "    \"\"\"ëª¨ë¸ í‰ê°€ (êµ¬ì¡° ì •ë³´ í¬í•¨)\"\"\"\n",
    "    logger.info(f\"ëª¨ë¸ ë¡œë“œ: {model_path}\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    padding_value = -999999.0\n",
    "    criterion = MaskedMSELoss(padding_value)\n",
    "    \n",
    "    # êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ë“¤\n",
    "    structured_predictions = []\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    logger.info(\"í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            continuous_data = batch[\"continuous_data\"].to(device)\n",
    "            categorical_data = batch[\"categorical_data\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "            masks = batch[\"masks\"].to(device)\n",
    "            sequence_lengths = batch[\"sequence_lengths\"]\n",
    "            \n",
    "            # êµ¬ì¡° ì •ë³´ ì¶”ì¶œ\n",
    "            timekey_hrs = batch[\"timekey_hrs\"]\n",
    "            oper_ids_list = batch[\"oper_ids_list\"]\n",
    "            \n",
    "            predictions = model(continuous_data, categorical_data, masks, sequence_lengths)\n",
    "            loss = criterion(predictions, targets, masks)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # CPUë¡œ ë³€í™˜\n",
    "            predictions_cpu = predictions.cpu()\n",
    "            targets_cpu = targets.cpu()\n",
    "            masks_cpu = masks.cpu()\n",
    "            \n",
    "            # ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œì— ëŒ€í•´ êµ¬ì¡°í™”ëœ ê²°ê³¼ ìƒì„±\n",
    "            batch_size = predictions_cpu.shape[0]\n",
    "            for sample_idx in range(batch_size):\n",
    "                timekey_hr = timekey_hrs[sample_idx]\n",
    "                oper_ids = oper_ids_list[sample_idx]\n",
    "                sample_predictions = predictions_cpu[sample_idx]\n",
    "                sample_targets = targets_cpu[sample_idx]\n",
    "                sample_masks = masks_cpu[sample_idx]\n",
    "                \n",
    "                # ê° ì‹œí€€ìŠ¤ ìœ„ì¹˜ì— ëŒ€í•´\n",
    "                for seq_idx in range(sample_predictions.shape[0]):\n",
    "                    # íŒ¨ë”©ë˜ì§€ ì•Šì€ ìœ„ì¹˜ë§Œ ì²˜ë¦¬\n",
    "                    if not sample_masks[seq_idx] and oper_ids[seq_idx] is not None:\n",
    "                        pred_val = sample_predictions[seq_idx].item()\n",
    "                        target_val = sample_targets[seq_idx].item()\n",
    "                        oper_id = oper_ids[seq_idx]\n",
    "                        \n",
    "                        structured_predictions.append({\n",
    "                            'timekey_hr': timekey_hr,\n",
    "                            'oper_id': oper_id,\n",
    "                            'predicted': pred_val,\n",
    "                            'actual': target_val\n",
    "                        })\n",
    "                        \n",
    "                        all_predictions.append(pred_val)\n",
    "                        all_targets.append(target_val)\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    \n",
    "    # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    mse = np.mean((all_predictions - all_targets) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(all_predictions - all_targets))\n",
    "    \n",
    "    epsilon = 1e-8\n",
    "    abs_targets = np.abs(all_targets)\n",
    "    abs_errors = np.abs(all_predictions - all_targets)\n",
    "    safe_targets = np.maximum(abs_targets, epsilon)\n",
    "    mape = np.mean(abs_errors / safe_targets * 100)\n",
    "    \n",
    "    metrics = {\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"mape\": mape,\n",
    "        \"valid_count\": len(all_predictions)\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"í…ŒìŠ¤íŠ¸ ê²°ê³¼: RMSE={rmse:.4f}, MAE={mae:.4f}, MAPE={mape:.2f}%\")\n",
    "    logger.info(f\"êµ¬ì¡°í™”ëœ ì˜ˆì¸¡ ê²°ê³¼: {len(structured_predictions):,}ê°œ\")\n",
    "    \n",
    "    return {\n",
    "        \"test_loss\": avg_loss,\n",
    "        \"metrics\": metrics,\n",
    "        \"predictions\": all_predictions,\n",
    "        \"targets\": all_targets,\n",
    "        \"structured_predictions\": structured_predictions  # ì¶”ê°€\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ëª¨ë¸ë§\")\n",
    "    parser.add_argument(\"--config-dir\", default=\"configs\", help=\"ì„¤ì • íŒŒì¼ ë””ë ‰í† ë¦¬\")\n",
    "    parser.add_argument(\"--mode\", choices=[\"train\", \"eval\"], default=\"train\", help=\"ì‹¤í–‰ ëª¨ë“œ\")\n",
    "    parser.add_argument(\"--model-path\", default=None, help=\"í‰ê°€ìš© ëª¨ë¸ ê²½ë¡œ\")\n",
    "    parser.add_argument(\"--gpu\", type=int, default=0, help=\"GPU ë²ˆí˜¸\")\n",
    "    parser.add_argument(\"--exp-name\", default=None, help=\"ì‹¤í—˜ëª…\")\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "    \n",
    "    # ì„¤ì • ë¡œë“œ\n",
    "    config = load_config(args.config_dir)\n",
    "    set_random_seeds(42)\n",
    "    \n",
    "    # ì‹¤í—˜ëª… ì„¤ì •\n",
    "    if args.exp_name:\n",
    "        exp_name = args.exp_name\n",
    "    else:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_type = config.get(\"model_type\", \"lstm\")\n",
    "        exp_name = f\"{model_type}_{timestamp}\"\n",
    "    \n",
    "    # ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "    save_dir = config.get(\"save_dir\", \"models\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model_save_path = os.path.join(save_dir, f\"{exp_name}.pth\")\n",
    "    \n",
    "    # ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "    device = torch.device(f\"cuda:{args.gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # ë°ì´í„°ë¡œë” ìƒì„±\n",
    "    logger.info(\"ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "    train_loader, val_loader, test_loader, categorical_processor = create_dataloaders(config)\n",
    "    \n",
    "    # ëª¨ë¸ ìƒì„±\n",
    "    vocab_sizes = categorical_processor.get_vocab_sizes()\n",
    "    continuous_dim = len(config[\"continuous_columns\"])\n",
    "    \n",
    "    model = create_model(config, vocab_sizes, continuous_dim)\n",
    "    \n",
    "    if args.mode == \"train\":\n",
    "        # í›ˆë ¨\n",
    "        logger.info(\"í›ˆë ¨ ì‹œì‘...\")\n",
    "        train_results = train_model(\n",
    "            model, train_loader, val_loader, config, device, model_save_path\n",
    "        )\n",
    "        \n",
    "        logger.info(\"í›ˆë ¨ ì™„ë£Œ, í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "        test_results = evaluate_model(model, test_loader, device, model_save_path)\n",
    "        \n",
    "    else:\n",
    "        # í‰ê°€\n",
    "        if not args.model_path:\n",
    "            raise ValueError(\"--model-path must be provided in eval mode\")\n",
    "        test_results = evaluate_model(model, test_loader, device, args.model_path)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    results = {\n",
    "        \"exp_name\": exp_name,\n",
    "        \"config\": config,\n",
    "        \"test_metrics\": test_results[\"metrics\"],\n",
    "        \"model_info\": {\n",
    "            \"total_parameters\": sum(p.numel() for p in model.parameters()),\n",
    "            \"model_type\": config.get(\"model_type\", \"lstm\")\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results_path = os.path.join(save_dir, f\"{exp_name}_results.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2, default=str)\n",
    "    \n",
    "    # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
    "    if \"structured_predictions\" in test_results and test_results[\"structured_predictions\"]:\n",
    "        # êµ¬ì¡°í™”ëœ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (timekey_hr, oper_id í¬í•¨)\n",
    "        structured_df = pd.DataFrame(test_results[\"structured_predictions\"])\n",
    "        structured_df[\"error\"] = structured_df[\"predicted\"] - structured_df[\"actual\"]\n",
    "        structured_df[\"abs_error\"] = structured_df[\"error\"].abs()\n",
    "        structured_df[\"abs_percent_error\"] = (\n",
    "            structured_df[\"abs_error\"] / structured_df[\"actual\"].abs().clip(lower=1e-8) * 100\n",
    "        )\n",
    "        \n",
    "        # êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ ë©”ì¸ ì˜ˆì¸¡ íŒŒì¼ë¡œ ì €ì¥\n",
    "        predictions_path = os.path.join(save_dir, f\"{exp_name}_predictions.csv\")\n",
    "        structured_df.to_csv(predictions_path, index=False)\n",
    "        \n",
    "        logger.info(f\"  - êµ¬ì¡°í™”ëœ ì˜ˆì¸¡ ê²°ê³¼: {predictions_path}\")\n",
    "        logger.info(f\"  - ì €ì¥ëœ ì˜ˆì¸¡ ê°œìˆ˜: {len(structured_df):,}ê°œ\")\n",
    "        logger.info(f\"  - ê³ ìœ í•œ timekey_hr: {structured_df['timekey_hr'].nunique()}ê°œ\")\n",
    "        logger.info(f\"  - ê³ ìœ í•œ oper_id: {structured_df['oper_id'].nunique()}ê°œ\")\n",
    "        \n",
    "    else:\n",
    "        # êµ¬ì¡°í™”ëœ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì €ì¥ (í˜¸í™˜ì„± ìœ ì§€)\n",
    "        predictions_df = pd.DataFrame({\n",
    "            \"actual\": test_results[\"targets\"],\n",
    "            \"predicted\": test_results[\"predictions\"],\n",
    "            \"residual\": test_results[\"targets\"] - test_results[\"predictions\"],\n",
    "            \"abs_error\": np.abs(test_results[\"targets\"] - test_results[\"predictions\"]),\n",
    "            \"abs_percent_error\": (\n",
    "                np.abs(test_results[\"targets\"] - test_results[\"predictions\"]) / \n",
    "                np.maximum(np.abs(test_results[\"targets\"]), 1e-8) * 100\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        predictions_path = os.path.join(save_dir, f\"{exp_name}_predictions.csv\")\n",
    "        predictions_df.to_csv(predictions_path, index=False)\n",
    "        \n",
    "        logger.info(f\"  - ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼: {predictions_path}\")\n",
    "        logger.info(f\"  - ì €ì¥ëœ ì˜ˆì¸¡ ê°œìˆ˜: {len(predictions_df):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 14:25:18,724 - INFO - Using device: cuda:0\n",
      "2025-08-31 14:25:18,728 - INFO - ë°ì´í„° ë¡œë”© ì¤‘...\n",
      "2025-08-31 14:38:12,837 - INFO - ë²”ì£¼í˜• ë³€ìˆ˜ë³„ ê³ ìœ ê°’ ê°œìˆ˜:\n",
      "2025-08-31 14:38:12,838 - INFO -   oper_group: 277ê°œ\n",
      "2025-08-31 14:38:12,839 - INFO -   days: 7ê°œ\n",
      "2025-08-31 14:38:12,839 - INFO -   shift: 3ê°œ\n",
      "2025-08-31 14:38:12,840 - INFO -   x1: 20ê°œ\n",
      "2025-08-31 14:38:17,881 - INFO - ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ:\n",
      "2025-08-31 14:38:17,882 - INFO -   - ì´ ì‹œí€€ìŠ¤ ìˆ˜: 2136\n",
      "2025-08-31 14:38:17,883 - INFO -   - ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 50\n",
      "2025-08-31 14:38:17,883 - INFO -   - íŠ¹ì„± ì°¨ì›: 52\n",
      "2025-08-31 14:38:17,884 - INFO -   - íŒ¨ë”©ê°’: -999999.0\n",
      "2025-08-31 14:38:20,385 - INFO - ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ:\n",
      "2025-08-31 14:38:20,386 - INFO -   - ì´ ì‹œí€€ìŠ¤ ìˆ˜: 2136\n",
      "2025-08-31 14:38:20,386 - INFO -   - ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 50\n",
      "2025-08-31 14:38:20,387 - INFO -   - íŠ¹ì„± ì°¨ì›: 52\n",
      "2025-08-31 14:38:20,387 - INFO -   - íŒ¨ë”©ê°’: -999999.0\n",
      "2025-08-31 14:38:23,052 - INFO - ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ:\n",
      "2025-08-31 14:38:23,053 - INFO -   - ì´ ì‹œí€€ìŠ¤ ìˆ˜: 2136\n",
      "2025-08-31 14:38:23,054 - INFO -   - ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 50\n",
      "2025-08-31 14:38:23,054 - INFO -   - íŠ¹ì„± ì°¨ì›: 52\n",
      "2025-08-31 14:38:23,055 - INFO -   - íŒ¨ë”©ê°’: -999999.0\n",
      "2025-08-31 14:38:23,056 - INFO - ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ:\n",
      "2025-08-31 14:38:23,056 - INFO -   - í›ˆë ¨ ìƒ˜í”Œ: 2136\n",
      "2025-08-31 14:38:23,056 - INFO -   - ê²€ì¦ ìƒ˜í”Œ: 2136\n",
      "2025-08-31 14:38:23,057 - INFO -   - í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: 2136\n",
      "2025-08-31 14:38:23,057 - INFO -   - ë°°ì¹˜ í¬ê¸°: 364\n",
      "2025-08-31 14:38:23,238 - INFO - ëª¨ë¸ ìƒì„± ì™„ë£Œ:\n",
      "2025-08-31 14:38:23,239 - INFO -   - ëª¨ë¸ íƒ€ì…: lstm\n",
      "2025-08-31 14:38:23,239 - INFO -   - ì´ íŒŒë¼ë¯¸í„° ìˆ˜: 617,113\n",
      "2025-08-31 14:38:23,240 - INFO -   - í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: 617,113\n",
      "2025-08-31 14:38:23,240 - INFO - í›ˆë ¨ ì‹œì‘...\n",
      "/usr/local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-08-31 14:38:24,448 - INFO - í›ˆë ¨ ì‹œì‘: 100 ì—í­, í•™ìŠµë¥  0.001\n",
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]2025-08-31 14:38:26,300 - INFO - Epoch   1: Train Loss=0.2122, Val Loss=0.0124, Train MAPE=85057.35%, Val MAPE=43842.21%\n",
      "Training Progress:   0%|          | 0/100 [00:01<?, ?it/s, T_Loss=0.2122, V_Loss=0.0124, V_MAPE=43842.21%, Best=inf, Patience=0/20]2025-08-31 14:38:26,326 - INFO -   â†’ Best model saved! (Val Loss: 0.0124)\n",
      "Training Progress:   1%|          | 1/100 [00:01<03:05,  1.88s/it, T_Loss=0.2122, V_Loss=0.0124, V_MAPE=43842.21%, Best=inf, Patience=0/20]2025-08-31 14:38:27,695 - INFO - Epoch   2: Train Loss=0.1530, Val Loss=0.0283, Train MAPE=266213.09%, Val MAPE=38449.30%\n",
      "Training Progress:   2%|â–         | 2/100 [00:03<02:34,  1.58s/it, T_Loss=0.1530, V_Loss=0.0283, V_MAPE=38449.30%, Best=0.0124, Patience=0/20]2025-08-31 14:38:29,003 - INFO - Epoch   3: Train Loss=0.1375, Val Loss=0.0125, Train MAPE=248363.36%, Val MAPE=55303.24%\n",
      "Training Progress:   3%|â–         | 3/100 [00:04<02:21,  1.45s/it, T_Loss=0.1375, V_Loss=0.0125, V_MAPE=55303.24%, Best=0.0124, Patience=1/20]2025-08-31 14:38:31,007 - INFO - Epoch   4: Train Loss=0.1291, Val Loss=0.0113, Train MAPE=239184.33%, Val MAPE=47051.70%\n",
      "Training Progress:   3%|â–         | 3/100 [00:06<02:21,  1.45s/it, T_Loss=0.1291, V_Loss=0.0113, V_MAPE=47051.70%, Best=0.0124, Patience=2/20]2025-08-31 14:38:31,078 - INFO -   â†’ Best model saved! (Val Loss: 0.0113)\n",
      "Training Progress:   4%|â–         | 4/100 [00:06<02:43,  1.70s/it, T_Loss=0.1291, V_Loss=0.0113, V_MAPE=47051.70%, Best=0.0124, Patience=2/20]2025-08-31 14:38:32,435 - INFO - Epoch   5: Train Loss=0.1258, Val Loss=0.0109, Train MAPE=276576.88%, Val MAPE=49548.10%\n",
      "Training Progress:   4%|â–         | 4/100 [00:07<02:43,  1.70s/it, T_Loss=0.1258, V_Loss=0.0109, V_MAPE=49548.10%, Best=0.0113, Patience=0/20]2025-08-31 14:38:32,459 - INFO -   â†’ Best model saved! (Val Loss: 0.0109)\n",
      "Training Progress:   5%|â–Œ         | 5/100 [00:08<02:30,  1.58s/it, T_Loss=0.1258, V_Loss=0.0109, V_MAPE=49548.10%, Best=0.0113, Patience=0/20]2025-08-31 14:38:33,797 - INFO - Epoch   6: Train Loss=0.1254, Val Loss=0.0122, Train MAPE=291849.16%, Val MAPE=56635.50%\n",
      "Training Progress:   6%|â–Œ         | 6/100 [00:09<02:21,  1.50s/it, T_Loss=0.1254, V_Loss=0.0122, V_MAPE=56635.50%, Best=0.0109, Patience=0/20]2025-08-31 14:38:35,124 - INFO - Epoch   7: Train Loss=0.1249, Val Loss=0.0113, Train MAPE=268570.69%, Val MAPE=49640.14%\n",
      "Training Progress:   7%|â–‹         | 7/100 [00:10<02:14,  1.44s/it, T_Loss=0.1249, V_Loss=0.0113, V_MAPE=49640.14%, Best=0.0109, Patience=1/20]2025-08-31 14:38:36,500 - INFO - Epoch   8: Train Loss=0.1246, Val Loss=0.0113, Train MAPE=256918.30%, Val MAPE=53991.79%\n",
      "Training Progress:   8%|â–Š         | 8/100 [00:12<02:10,  1.42s/it, T_Loss=0.1246, V_Loss=0.0113, V_MAPE=53991.79%, Best=0.0109, Patience=2/20]2025-08-31 14:38:37,809 - INFO - Epoch   9: Train Loss=0.1241, Val Loss=0.0110, Train MAPE=249341.88%, Val MAPE=48591.14%\n",
      "Training Progress:   9%|â–‰         | 9/100 [00:13<02:06,  1.39s/it, T_Loss=0.1241, V_Loss=0.0110, V_MAPE=48591.14%, Best=0.0109, Patience=3/20]2025-08-31 14:38:39,157 - INFO - Epoch  10: Train Loss=0.1235, Val Loss=0.0116, Train MAPE=286960.72%, Val MAPE=53061.81%\n",
      "Training Progress:  10%|â–ˆ         | 10/100 [00:14<02:03,  1.37s/it, T_Loss=0.1235, V_Loss=0.0116, V_MAPE=53061.81%, Best=0.0109, Patience=4/20]2025-08-31 14:38:40,497 - INFO - Epoch  11: Train Loss=0.1234, Val Loss=0.0113, Train MAPE=268388.28%, Val MAPE=49638.86%\n",
      "Training Progress:  11%|â–ˆ         | 11/100 [00:16<02:01,  1.36s/it, T_Loss=0.1234, V_Loss=0.0113, V_MAPE=49638.86%, Best=0.0109, Patience=5/20]2025-08-31 14:38:41,828 - INFO - Epoch  12: Train Loss=0.1227, Val Loss=0.0111, Train MAPE=281134.53%, Val MAPE=49044.41%\n",
      "Training Progress:  12%|â–ˆâ–        | 12/100 [00:17<01:59,  1.35s/it, T_Loss=0.1227, V_Loss=0.0111, V_MAPE=49044.41%, Best=0.0109, Patience=6/20]2025-08-31 14:38:43,142 - INFO - Epoch  13: Train Loss=0.1221, Val Loss=0.0118, Train MAPE=312178.00%, Val MAPE=50572.58%\n",
      "Training Progress:  13%|â–ˆâ–        | 13/100 [00:18<01:56,  1.34s/it, T_Loss=0.1221, V_Loss=0.0118, V_MAPE=50572.58%, Best=0.0109, Patience=7/20]2025-08-31 14:38:44,466 - INFO - Epoch  14: Train Loss=0.1222, Val Loss=0.0116, Train MAPE=254217.98%, Val MAPE=55119.02%\n",
      "Training Progress:  14%|â–ˆâ–        | 14/100 [00:20<01:54,  1.34s/it, T_Loss=0.1222, V_Loss=0.0116, V_MAPE=55119.02%, Best=0.0109, Patience=8/20]2025-08-31 14:38:45,792 - INFO - Epoch  15: Train Loss=0.1231, Val Loss=0.0116, Train MAPE=273660.66%, Val MAPE=52123.32%\n",
      "Training Progress:  15%|â–ˆâ–Œ        | 15/100 [00:21<01:53,  1.33s/it, T_Loss=0.1231, V_Loss=0.0116, V_MAPE=52123.32%, Best=0.0109, Patience=9/20]2025-08-31 14:38:47,163 - INFO - Epoch  16: Train Loss=0.1222, Val Loss=0.0116, Train MAPE=267461.41%, Val MAPE=52613.26%\n",
      "Training Progress:  16%|â–ˆâ–Œ        | 16/100 [00:22<01:52,  1.34s/it, T_Loss=0.1222, V_Loss=0.0116, V_MAPE=52613.26%, Best=0.0109, Patience=10/20]2025-08-31 14:38:48,627 - INFO - Epoch  17: Train Loss=0.1211, Val Loss=0.0115, Train MAPE=283100.66%, Val MAPE=52253.86%\n",
      "Training Progress:  17%|â–ˆâ–‹        | 17/100 [00:24<01:54,  1.38s/it, T_Loss=0.1211, V_Loss=0.0115, V_MAPE=52253.86%, Best=0.0109, Patience=11/20]2025-08-31 14:38:49,973 - INFO - Epoch  18: Train Loss=0.1203, Val Loss=0.0111, Train MAPE=275078.34%, Val MAPE=48055.20%\n",
      "Training Progress:  18%|â–ˆâ–Š        | 18/100 [00:25<01:52,  1.37s/it, T_Loss=0.1203, V_Loss=0.0111, V_MAPE=48055.20%, Best=0.0109, Patience=12/20]2025-08-31 14:38:51,355 - INFO - Epoch  19: Train Loss=0.1202, Val Loss=0.0114, Train MAPE=275046.00%, Val MAPE=53828.34%\n",
      "Training Progress:  19%|â–ˆâ–‰        | 19/100 [00:26<01:51,  1.37s/it, T_Loss=0.1202, V_Loss=0.0114, V_MAPE=53828.34%, Best=0.0109, Patience=13/20]2025-08-31 14:38:52,717 - INFO - Epoch  20: Train Loss=0.1183, Val Loss=0.0113, Train MAPE=291573.38%, Val MAPE=49848.51%\n",
      "Training Progress:  20%|â–ˆâ–ˆ        | 20/100 [00:28<01:49,  1.37s/it, T_Loss=0.1183, V_Loss=0.0113, V_MAPE=49848.51%, Best=0.0109, Patience=14/20]2025-08-31 14:38:54,100 - INFO - Epoch  21: Train Loss=0.1182, Val Loss=0.0113, Train MAPE=324644.19%, Val MAPE=49536.65%\n",
      "Training Progress:  21%|â–ˆâ–ˆ        | 21/100 [00:29<01:48,  1.37s/it, T_Loss=0.1182, V_Loss=0.0113, V_MAPE=49536.65%, Best=0.0109, Patience=15/20]2025-08-31 14:38:55,437 - INFO - Epoch  22: Train Loss=0.1178, Val Loss=0.0114, Train MAPE=298139.69%, Val MAPE=49774.39%\n",
      "Training Progress:  22%|â–ˆâ–ˆâ–       | 22/100 [00:30<01:46,  1.36s/it, T_Loss=0.1178, V_Loss=0.0114, V_MAPE=49774.39%, Best=0.0109, Patience=16/20]2025-08-31 14:38:56,763 - INFO - Epoch  23: Train Loss=0.1168, Val Loss=0.0115, Train MAPE=303203.00%, Val MAPE=48601.57%\n",
      "Training Progress:  23%|â–ˆâ–ˆâ–       | 23/100 [00:32<01:44,  1.35s/it, T_Loss=0.1168, V_Loss=0.0115, V_MAPE=48601.57%, Best=0.0109, Patience=17/20]2025-08-31 14:38:58,101 - INFO - Epoch  24: Train Loss=0.1180, Val Loss=0.0114, Train MAPE=286847.53%, Val MAPE=48936.80%\n",
      "Training Progress:  24%|â–ˆâ–ˆâ–       | 24/100 [00:33<01:42,  1.35s/it, T_Loss=0.1180, V_Loss=0.0114, V_MAPE=48936.80%, Best=0.0109, Patience=18/20]2025-08-31 14:38:59,412 - INFO - Epoch  25: Train Loss=0.1168, Val Loss=0.0113, Train MAPE=245007.88%, Val MAPE=52410.64%\n",
      "Training Progress:  24%|â–ˆâ–ˆâ–       | 24/100 [00:34<01:42,  1.35s/it, T_Loss=0.1168, V_Loss=0.0113, V_MAPE=52410.64%, Best=0.0109, Patience=19/20]2025-08-31 14:38:59,414 - INFO - Early stopping at epoch 25\n",
      "Training Progress:  24%|â–ˆâ–ˆâ–       | 24/100 [00:34<01:50,  1.46s/it, T_Loss=0.1168, V_Loss=0.0113, V_MAPE=52410.64%, Best=0.0109, Patience=19/20]\n",
      "2025-08-31 14:38:59,417 - INFO - í›ˆë ¨ ì™„ë£Œ, í…ŒìŠ¤íŠ¸ ì‹œì‘...\n",
      "2025-08-31 14:38:59,418 - INFO - ëª¨ë¸ ë¡œë“œ: 250831_test/lstm_20250831_142503.pth\n",
      "/tmp/ipykernel_614454/118785919.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "2025-08-31 14:38:59,443 - INFO - í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.07it/s]\n",
      "2025-08-31 14:39:00,643 - INFO - í…ŒìŠ¤íŠ¸ ê²°ê³¼: RMSE=0.1112, MAE=0.0660, MAPE=27890.64%\n",
      "2025-08-31 14:39:00,644 - INFO - êµ¬ì¡°í™”ëœ ì˜ˆì¸¡ ê²°ê³¼: 106,784ê°œ\n",
      "2025-08-31 14:39:01,351 - INFO -   - êµ¬ì¡°í™”ëœ ì˜ˆì¸¡ ê²°ê³¼: 250831_test/lstm_20250831_142503_predictions.csv\n",
      "2025-08-31 14:39:01,352 - INFO -   - ì €ì¥ëœ ì˜ˆì¸¡ ê°œìˆ˜: 106,784ê°œ\n",
      "2025-08-31 14:39:01,354 - INFO -   - ê³ ìœ í•œ timekey_hr: 2136ê°œ\n",
      "2025-08-31 14:39:01,361 - INFO -   - ê³ ìœ í•œ oper_id: 84ê°œ\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê°€ì´ë“œ\n",
    "\n",
    "### 1. ëª¨ë¸ë³„ ê¶Œì¥ ì„¤ì •\n",
    "\n",
    "#### **LSTM/GRU (ê¸°ë³¸)**\n",
    "```yaml\n",
    "model_type: \"lstm\"\n",
    "hidden_dim: 128\n",
    "num_layers: 2\n",
    "bidirectional: true\n",
    "dropout: 0.1\n",
    "```\n",
    "\n",
    "#### **LSTM + Self-Attention**\n",
    "```yaml\n",
    "model_type: \"lstm_attention\"\n",
    "hidden_dim: 128\n",
    "num_layers: 2\n",
    "num_attention_heads: 8\n",
    "bidirectional: true\n",
    "dropout: 0.2\n",
    "```\n",
    "\n",
    "#### **CNN 1D**\n",
    "```yaml\n",
    "model_type: \"cnn1d\"\n",
    "kernel_sizes: [3, 5, 7]\n",
    "num_filters: 64\n",
    "dropout: 0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ì„±ëŠ¥ ìµœì í™” íŒ\n",
    "\n",
    "#### **ê³¼ì í•© ë°©ì§€**\n",
    "```yaml\n",
    "dropout: 0.3\n",
    "patience: 10\n",
    "learning_rate: 0.0001\n",
    "```\n",
    "\n",
    "#### **ë¹ ë¥¸ ìˆ˜ë ´**\n",
    "```yaml\n",
    "learning_rate: 0.01\n",
    "scheduler_patience: 5\n",
    "num_attention_heads: 4  # Attention ëª¨ë¸ì˜ ê²½ìš°\n",
    "```\n",
    "\n",
    "#### **ë©”ëª¨ë¦¬ ìµœì í™”**\n",
    "```yaml\n",
    "max_sequence_length: 30\n",
    "batch_size: 16\n",
    "num_layers: 1\n",
    "bidirectional: false\n",
    "```\n",
    "\n",
    "## ğŸ“ ì‹¤í–‰ ì˜ˆì‹œ\n",
    "\n",
    "### ê¸°ë³¸ í›ˆë ¨\n",
    "```bash\n",
    "python main.py --mode train --gpu 0\n",
    "```\n",
    "\n",
    "### íŠ¹ì • ëª¨ë¸ í›ˆë ¨\n",
    "```bash\n",
    "# LSTM with Attention\n",
    "python main.py --mode train --exp-name lstm_attention_exp1\n",
    "\n",
    "# CNN 1D  \n",
    "python main.py --mode train --exp-name cnn1d_exp1\n",
    "\n",
    "# ì„¤ì • ë³€ê²½ í›„\n",
    "python main.py --mode train --config-dir ./my_configs\n",
    "```\n",
    "\n",
    "### ëª¨ë¸ í‰ê°€\n",
    "```bash\n",
    "python main.py --mode eval --model-path ./models/lstm_20241201_120000.pth\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì°¸ê³ **: ì´ í”„ë¡œì íŠ¸ëŠ” ì‹œí€€ìŠ¤ ëª¨ë¸ë§ ê´€ì ì—ì„œ ê³µì • ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ë©°, timekey_hr ë‚´ oper_id ìˆœì„œë¥¼ ê³ ë ¤í•œ sequence-to-sequence ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
